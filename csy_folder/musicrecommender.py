# -*- coding: utf-8 -*-
"""MusicRecommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hIt-lt40MFW49hBysyPbjaMkya4wcvqw
"""

import os
import glob
import pandas as pd
import numpy as np
import json

from tqdm.notebook import tqdm

from collections import defaultdict
import random

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model

import pickle

def get_path(filename):
  return f'/content/drive/MyDrive/Data/{filename}'

def get_data_from_pickle(path):
    with open(path, "rb") as f:
        data = pickle.load(f)
    return data

def write_data_to_pickle(data, path):
    with open(path, "wb") as f:
        f.write(pickle.dumps(data))

tag_vectors = get_data_from_pickle(get_path('tag_vectors'))
cluster_centers = get_data_from_pickle(get_path('kmeans15.cluster_centers_.pickle'))
unique_tag_list = get_data_from_pickle(get_path('unique_tag_list.pickle'))
tag_dict = get_data_from_pickle(get_path('tag_dict.pickle'))

df_meta = pd.read_csv(get_path('Meta_v1.csv'))
# df = pd.read_json(get_path('data_version_2.json'))

tag_matrix = np.array(tag_vectors)

tag2idx = {tag: i for i, tag in enumerate(unique_tag_list)}
idx2tag = {i: tag for i, tag in enumerate(unique_tag_list)}

df = df.reset_index(drop=True)

unique_songs = list(set([song for songs in df.songs2 for song in songs]))

song_idx2new_idx = {song_id: idx for idx, song_id in enumerate(unique_songs)}
new_idx2song_idx = {idx: song_id for idx, song_id in enumerate(unique_songs)}


genres_set = list(set([genre for genres in df_meta.gnrs for genre in genres]))

df_meta['new_id'] = df_meta.id.map(lambda x: song_idx2new_idx.get(int(x)))

df

df['tagIds'] = df.tags.map(lambda x: [tag2idx.get(tag) for tag in x])

tag_cluster_ids = [
    [tag2idx[tag] for tag in tag_dict[key]]
    for key in range(15)
]

min_tag_count = 2

df_clusters = [
    df[df.tagIds.map(lambda x: np.intersect1d(tag_cluster_ids[key], x, assume_unique=True).shape[0] >= min_tag_count )]
    for key in range(15)
]

cluster_songs = []

for key in range(15):
    cluster_songs.append(list(set([song for songs in df_clusters[key].songs2 for song in songs])))
    print(f"{key} : {df_clusters[key].shape} / {len(cluster_songs[key])}")

def get_recommendation_model(tag_num, music_num, embedding_matrix, latent_features=10, trainable=True):
  tag = Input(shape=(1,), dtype='int32')
  item = Input(shape=(1,), dtype='int32')

  # User embedding for GMF
  gmf_tag_embedding = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],
            input_length=1, embeddings_initializer=keras.initializers.Constant(embedding_matrix),
            trainable=trainable, name='tag_embedding')(tag)
  
  # gmf_tag_embedding = Embedding(tag_num, latent_features, input_length=user.shape[1])(tag)
  gmf_tag_embedding = Flatten()(gmf_tag_embedding)

  # Item embedding for GMF
  gmf_item_embedding = Embedding(music_num, latent_features, input_length=item.shape[1])(item)
  gmf_item_embedding = Flatten()(gmf_item_embedding)

  # GMF layers
  gmf_mul =  Multiply()([gmf_tag_embedding, gmf_item_embedding])

  # User embedding for MLP
  mlp_tag_embedding = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],
            input_length=1, embeddings_initializer=keras.initializers.Constant(embedding_matrix),
            trainable=trainable, name='tag_embedding2')(tag)
  mlp_tag_embedding = Flatten()(mlp_tag_embedding)

  # Item embedding for MLP
  mlp_item_embedding = Embedding(music_num, 32, input_length=item.shape[1])(item)
  mlp_item_embedding = Flatten()(mlp_item_embedding)

  # MLP layers
  mlp_concat = Concatenate()([mlp_tag_embedding, mlp_item_embedding])
  mlp_dropout = Dropout(0.2)(mlp_concat)

  # Layer1
  mlp_layer_1 = Dense(units=64, activation='relu', name='mlp_layer1')(mlp_dropout)  # (64,1)
  mlp_dropout1 = Dropout(rate=0.2, name='dropout1')(mlp_layer_1)                    # (64,1)
  mlp_batch_norm1 = BatchNormalization(name='batch_norm1')(mlp_dropout1)            # (64,1)

  # Layer2
  mlp_layer_2 = Dense(units=32, activation='relu', name='mlp_layer2')(mlp_batch_norm1)  # (32,1)
  mlp_dropout2 = Dropout(rate=0.2, name='dropout2')(mlp_layer_2)                        # (32,1)
  mlp_batch_norm2 = BatchNormalization(name='batch_norm2')(mlp_dropout2)                # (32,1)

  # Layer3
  mlp_layer_3 = Dense(units=16, activation='relu', name='mlp_layer3')(mlp_batch_norm2)  # (16,1)

  # Layer4
  mlp_layer_4 = Dense(units=8, activation='relu', name='mlp_layer4')(mlp_layer_3)       # (8,1)

  # merge GMF + MLP
  merged_vector = tf.keras.layers.concatenate([gmf_mul, mlp_layer_4]) # (16)

  # Output layer
  output_layer = Dense(1, kernel_initializer='lecun_uniform', name='output_layer')(merged_vector) # 1,1 / h(8,1)초기화

  # Model
  model = Model([tag, item], output_layer)
  model.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=["mse"])
  return model

class AllTagClusterModel(object):
    
    def __init__(self, _df, tag2idx):
        self._df = _df
        
        self.tag2id = tag2idx
        self._max_tag_len = len(tag2idx.keys())
        self._unique_tag_list = list(tag2idx.keys())
        
        self._unique_songs = list(set([song for songs in _df.songs2 for song in songs]))
        self._song_idx2new_idx = {song_id: idx for idx, song_id in enumerate(self._unique_songs)}
        self._new_idx2song_idx = {idx: song_id for idx, song_id in enumerate(self._unique_songs)}
        self._max_song_len = len(self._unique_songs)
        
        self._df['_song_ids'] = _df.songs2.map(lambda x: [self._song_idx2new_idx.get(song) for song in x])
        
        
    def preprocess(self, test_size=0.2, NEG_SAMPLE_NUM=20):
        _tag_song_freq = {i: defaultdict(int) for i in range(self._max_tag_len)}
        
        for tags, songs in tqdm(zip(self._df.tagIds, self._df._song_ids)):
            for song in songs:
                for tag in tags:
                    _tag_song_freq[tag][song] += 1
                    
        _df_freq = pd.DataFrame(_tag_song_freq).T
        _df_freq = _df_freq.stack().reset_index()
        _df_freq.columns = ['tag_id', 'song_id', 'freq']
        
        neg_data = []
        
        for tag in tqdm(self._unique_tag_list):
            i = NEG_SAMPLE_NUM
            new_tag_id = self.tag2id[tag]
            while i:
                random_id = self.get_random_music_id(self._max_song_len)
                if not _tag_song_freq[new_tag_id][random_id]:
                    neg_data.append((new_tag_id, random_id, 0))
                    i -= 1
        
        _df_neg = pd.DataFrame(neg_data, columns=_df_freq.columns)
        _df_freq = pd.concat([_df_freq, _df_neg]).sample(frac=1).reset_index(drop=True)
        _df_freq['freq2'] = _df_freq.freq.map(lambda x: 0.5 if x == 1 else (0 if x == 0 else 1))

        _df_over = _df_freq[_df_freq.freq > 1]
        
        test = _df_over.groupby('tag_id').apply(lambda x: self.get_test_sample(x, test_size)).reset_index()
        self.test = test.sample(frac=1).reset_index(drop=True)
        
        self.train = _df_freq[~_df_freq.index.isin(self.test.level_1)]
        
        self.x_train = [ 
                        self.train.tag_id.values.reshape(-1,1),
                        self.train.song_id.values.reshape(-1,1)
                        ]
        self.y_train = self.train.freq2.values
        
        self.x_test = [ 
                       self.test.tag_id.values.reshape(-1,1),
                       self.test.song_id.values.reshape(-1,1)
                       ]
        self.y_test = self.test.freq2.values
        
        
        
    def build_model(self, tag_matrix, EMBEDDING_SIZE=10, trainable=True):
        self.model = get_recommendation_model(self._max_tag_len, self._max_song_len, tag_matrix, EMBEDDING_SIZE, trainable)
        
    def fit(self, batch_size=64, epochs=10):
        self.history = self.model.fit(
            x=self.x_train,
            y=self.y_train,
            batch_size=batch_size,
            epochs=epochs,
            verbose=1,
            validation_data=(self.x_test, self.y_test),
        )
        
    def print_summary(self):
      print(self.model.summary())
        
    def predict(self, tag, k=50):
      _test_tag_id = self.tag2id.get(tag)

      if _test_tag_id == None: return []

      tags_input = np.array([_test_tag_id] * self._max_song_len).reshape(-1, 1)
      songs_input = np.array([*range(self._max_song_len)]).reshape(-1, 1)
      
      predicted = self.model.predict([tags_input, songs_input]).flatten()
      predicted = predicted.argsort()[-k:][::-1]

      return [self._new_idx2song_idx.get(new_id) for new_id in predicted]
        
    @staticmethod
    def get_test_sample(df, test_size=0.2, drop_column='tag_id'):
        return df.sample(frac=test_size).drop(drop_column, axis=1)
        
    @staticmethod
    def get_random_music_id(_max_len):
        return random.randint(0, _max_len-1)

all_tag_model = AllTagClusterModel(df, tag2idx)

all_tag_model.preprocess(test_size=0.2)

all_tag_model.build_model(tag_matrix)

all_tag_model.train.song_id.max()

all_tag_model.x_train



all_tag_model.fit(epochs=15, batch_size=256)

train = all_tag_model.train
train.song_id = train.song_id.map(lambda x: all_tag_model._new_idx2song_idx.get(x))

test = all_tag_model.test
test.song_id = test.song_id.map(lambda x: all_tag_model._new_idx2song_idx.get(x))

# all_tag_model.train = all_tag_model.train.song_id.map(lambda x: all_tag_model._song_idx2new_idx.get(x))
# all_tag_model.test = all_tag_model.test.song_id.map(lambda x: all_tag_model._song_idx2new_idx.get(x))

train.to_csv(get_path("train_v7.csv"), index=False)
test.to_csv(get_path("test_v7.csv"), index=False)

all_tag_model

all_tag_model.x_test





len(all_tag_model.y_train)

len([all_tag_model._new_idx2song_idx.get(new_id) for new_id in all_tag_model.x_test[1].ravel()] )

df_test = pd.DataFrame({
    "tag_id": all_tag_model.x_test[0].ravel(),
    "song_id": [all_tag_model._new_idx2song_idx.get(new_id) for new_id in all_tag_model.x_test[1].ravel()],
    "freq": all_tag_model.y_test
})

df_test.to_csv(get_path("test_v2.csv"), index=False)

import time

all_tag_model.x_test

k = 50

x_test =  all_tag_model.x_test
test_tags = list(set(x_test[0].ravel()))

recall_result = []
precision_result = []
prediction_result = []
true_result = []
correct_result = []

spent_result = []

for _test_tag_id in tqdm(test_tags):
    song_ids = x_test[1][x_test[0] == _test_tag_id]
    start_time = time.time()
    predicted = all_tag_model.predict(idx2tag[_test_tag_id], k)
    
    spent_result.append(time.time() - start_time)

    correct_count = np.intersect1d(song_ids, predicted).shape[0]

    correct_result.append(correct_count)
    prediction_result.append(predicted)
    true_result.append(song_ids)
    recall_result.append(correct_count / len(song_ids))
    precision_result.append(correct_count / k)

all_tag_model.model.summary()

all_tag_model

all_tag_model.model.save(get_path('all_model_v3'))

write_data_to_pickle(all_tag_model._new_idx2song_idx, get_path('all_model_v3_new2idx2songidx.pickle'))

test_pickle = get_data_from_pickle(get_path('all_model_v3_new2idx2songidx.pickle'))

test_pickle

tag_names = [idx2tag[tag_id] for tag_id in test_tags]
df_result = pd.DataFrame([tag_names, recall_result, precision_result, prediction_result, true_result, correct_result, spent_result]).T

df_result.columns = ['tag', 'recall', 'precision', 'prediction', 'true', 'correct', 'spent']

df_result

# df_result.to_json(get_path('Result_v2.json'))

df_result.info()

df_result.recall = df_result.recall.astype(float)
df_result.spent = df_result.spent.astype(float)

df_result[df_result.recall > 0].recall.mean()

df_result.spent.mean()

df_result.spent.mean()

df_result[df_result.recall > 0].recall.mean()

df_result[df_result.recall > 0].precision.mean()

df_result[df_result.recall > 0].spent.mean()

df_result2 = df_result[df_result.recall > 0]

df_result2 = df_result2.reset_index(drop=True)

df_result2['k50'] = df_result2.correct

df_result2['k25'] = [np.intersect1d(pred[:25], true).shape[0] for pred, true in zip(df_result2.prediction, df_result2.true)]
df_result2['k10'] = [np.intersect1d(pred[:10], true).shape[0] for pred, true in zip(df_result2.prediction, df_result2.true)]

df_result2

df_result2.to_json(get_path('final_result_all.json'))

df_result2

df_result2['recall@50'] = df_result2.k50 / df_result2.true.map(lambda x: len(x))
df_result2['recall@25'] = df_result2.k25 / df_result2.true.map(lambda x: len(x))
df_result2['recall@10'] = df_result2.k10 / df_result2.true.map(lambda x: len(x))

df_result2.mean()

df_result2['precision@50'] = df_result2.k50 / 50
df_result2['precision@25'] = df_result2.k25 / 25
df_result2['precision@10'] = df_result2.k10 / 10

df_result2[['precision@50','precision@25', 'precision@10']].mean().plot.bar(figsize=(16,9))

df_result2[['recall@50','recall@25', 'recall@10']].mean().plot.bar(figsize=(16,9))

df_result2.tag.values

df_result2.tag.nunique()

len(['연애', '유재석', '포근한', '연말', '짝사랑', '친구', '운전', '봄바람', '호텔', '잠들기전',
       '러브송', '흥겨운', '산책', '듣기좋은', '걸그룹', '요가', '드라이빙', '안녕', '파티',
       '비오는날', '추위', '감미로운', '재즈', '기억', '이브', 'UK', '추억회상', '여행', '가을밤',
       '센치한', '최신', '배경음악', '추석', '피트니스', '추억', '집', '남자', '살랑살랑', '어쿠스틱',
       '감성곡', '드라이브', '고속도로', '신나는', '가을비', '눈', '불금', '피아노', '연주',
       '성인가요', '댄스', '주말', '패션', '우울한', '벚꽃', '날씨', '커피', '노동요', '경쾌한',
       '나만의Best3', '정미애', '노래', '헤어짐', '팝', '댄스곡', '심쿵', '여유', '휴식', '아기',
       '새벽', 'SWAG', '우울', '침대', '12월', '뉴에이지', '낭만적인', '론뮤직', '공부할때',
       '우울할때', '명절', '2019년', '중독성', '엄마아리랑', '인디', 'DJ', '비', '자장가',
       '버스', '스타일', '까페', '퇴근', '핫한', '상큼한', '노래방', '상큼', 'EDM', '오디오',
       '혼자', '기분전환', 'cafe', '감성자극', '휴양지', '아이돌', '부드러운', '눈오는날', '아련한',
       '여름노래', '댄스댄스', 'electronica', '연휴', '가을', '알앤비', '토닥토닥', '장마',
       '가을감성', '트렌디', '꿀잠', '내마음의사진', '과거', '잔잔', '하우스', '와인', '고백', '신남',
       '봄노래', '쓸쓸', '데이식스', '느낌있는', '성탄절', '불면증', '전곡듣기', '월드', '귀성길',
       '최애곡', '디스코', '달달', '소울', '책읽을때', '슬픔', '운동', '사랑노래', '락', '잔잔한노래',
       '첫눈', '여름밤', '쌀쌀한', '시원한', '저녁', '낮잠', '일렉', '캐롤', '수고', 'kpop',
       '방콕', '혼자있을때', '메리크리스마스', '기분좋은', '포크', '빌로우', '아무로나미에', '꽃',
       '월요병', '분위기', '청량', '페스티벌', '추천곡', '내적댄스', '외로움', '클럽', '즐거운',
       '맑은', '스포츠', '미스터트롯', '열대야', '오르골', '감성발라드', '밤', '시작', '브릿팝',
       'EDMFloor', '빗소리', '트렌드', '조용한', '낙엽', '겨울밤', 'RnB', '2019', '몽환',
       '블랙뮤직', '겨울노래', '겨울', '휴일', '태교', '팝송', '새벽감성', '소나기', '그리움', '공감',
       'dance', '달달한', '신나는노래', '하늘', '그루브', '봄', '퓨전재즈', '회식', '일렉트로니카',
       '잔잔한', '힙합엘이', '이어폰', '힘들때', '설렘', '취향저격', '독서', '명상', '썸', '목소리',
       'TOP20', '내한', '랩', '더위', '송가인', 'Official_Chart', '따듯한', '띵곡들',
       '파워풀', '베스트', '연주곡', '셋리스트', '감성', '엄마', '재즈힙합', '바람', '헬스',
       '운동할때', '동요', '흐린날', '감성적인', '명곡', '감성충전', '임영웅', '집콕', '홍자', '별',
       '커피숍', 'pub', '크리스마스', '바다', '기분업', '안전운전', '봄캐롤', '추억의', '흥폭발',
       '겨울감성', '도시', '어린이집', '숨은명곡', '모닝콜', '꿀맛', '화창한', '라운지', '2000',
       '휴가', 'bgm', '여름휴가', '연인', '비오는날듣기좋은노래', '하루', '슬픈', '헬스장', 'Pop',
       '집중', '눈물', '아침', '두근두근', '즐거움', 'Rock', '차분한', '출근길', '이별', '계절',
       '스트레스', '봄날', '잠', '피크닉', '음색', '달콤', 'OST모음', '다이어트', '추운날', '띵곡',
       '알엔비', '콘서트', '오후', '시험', '트롯', '숙면', 'HOT', '회상', '우산', '대세',
       '싱어송라이터', '캐럴', '취저', '신나는_음악', '꿀성대', '흥', '설레임', '힙합', '애창곡',
       '이별노래', '카페', '매장', '음색깡패', '크리스마스노래', '여자', '스웩', '1990', '미스트롯',
       '2010', '퇴근길', '잠잘때', '공부', '설날', '쓸쓸한', '감각적인', '연주음악', '달콤한',
       '주제곡', '사랑', 'HIPHOPLE', '발라드', '생각', '여름', '힐링', '여자아이돌', '방탄',
       '센치', '커플', '첫사랑', '지하철', '위로', '매장음악', '좋은노래', '가사', '데이트',
       'Acoustic', '유산소', '솔로', '세련된', '비트', '스타일리시', '꿈', '야경', '편안한',
       '일상'])

df_result.sort_values('recall', ascending=False).head(10)

df_result.sort_values('correct', ascending=False).head(20)

df_meta[df_meta.id.isin(df_result.loc[61, 'prediction'])]



df_result['recall'].mean()

# Commented out IPython magic to ensure Python compatibility.
# %timeit predicted = all_tag_model.predict(idx2tag[_test_tag_id], k)

all_tag_model.model.save(get_path('All_Model_2'))





train = pd.read_csv(get_path("train_v7.csv"))
test = pd.read_csv(get_path("test_v7.csv"))

pivot_matrix = train.pivot_table('freq',  'tag_id', 'song_id', aggfunc='max')

pivot_matrix = pivot_matrix.fillna(0)

df_pivot = pivot_matrix

# Matrix Factorization
from sklearn.decomposition import TruncatedSVD

SVD = TruncatedSVD(n_components=12)
matrix = SVD.fit_transform(pivot_matrix)
matrix

# 피어슨 상관계수 구하기
import numpy as np

corr = np.corrcoef(matrix)
corr

import math
import scipy
from sklearn.decomposition import TruncatedSVD
from scipy.sparse.linalg import svds
from sklearn.model_selection import train_test_split

df_pivot.index.name = 'tags'
df_pivot.columns.name = 'songs'
df_pivot.head()

# matrix는 pivot_table 값을 numpy matrix로 만든 것 
matrix = df_pivot.values

# tag_ratings_mean은 tag의 평균 song 개수 
tag_ratings_mean = np.mean(matrix, axis = 1)

# R_user_mean : 사용자-영화에 대해 사용자 평균 평점을 뺀 것.
matrix_tag_mean = matrix - tag_ratings_mean.reshape(-1, 1)

matrix.shape

tag_ratings_mean.shape

# Commented out IPython magic to ensure Python compatibility.
# scipy에서 제공해주는 svd.  
# U 행렬, sigma 행렬, V 전치 행렬을 반환.
# %time U, sigma, Vt = svds(matrix_tag_mean, k = 12)

print(U.shape)
print(sigma.shape)
print(Vt.shape)

sigma = np.diag(sigma)

sigma.shape

# U, Sigma, Vt의 내적을 수행하면, 다시 원본 행렬로 복원이 된다. 
# 거기에 + 사용자 평균 rating을 적용한다. 
svd_tag_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + tag_ratings_mean.reshape(-1, 1)

df_svd_preds = pd.DataFrame(svd_tag_predicted_ratings, columns = df_pivot.columns)
df_svd_preds.head()

df_svd_preds.shape

k = 50
def svd_recommender(tag, df_svd_preds=df_svd_preds, k=50):
  return df_svd_preds.loc[tag2idx.get(tag), :].sort_values(ascending = False).head(k).index.tolist()



predicted_songs.values

df_pivot

test_tags = ['디즈니', '연애', '유재석', '고막남친', '포근한', '연말', '짝사랑', '운전', '봄바람',
       '잠들기전', '힘', '흥겨운', '신곡', '산책', '듣기좋은', '걸그룹', '파티', '비오는날', '추위',
       '비오는', '불토', '재즈', '이브', 'UK', '연애세포', '여행', '가을밤', '센치한', '록',
       '행복', '배경음악', '감성힙합', '추석', '추억', '지친', '집', '어쿠스틱', '감성곡', '드라이브',
       '고속도로', '신나는', '가을비', '트로트', '눈', '불금', '피아노', '발랄', '성인가요', '댄스',
       '주말', '패션', '우울한', '벚꽃', '날씨', '커피', '노동요', '수록곡', '힘내', '경쾌한',
       '정미애', '따뜻함', '노래', 'OfficialCharts', '헤어짐', '남자아이돌', '팝', '댄스곡',
       '정다경', '여유', '휴식', '새벽', '잔잔함', '2000년대', '나른', '우울', '12월',
       '뉴에이지', '우울할때', '명절', '2019년', '중독성', '엄마아리랑', '인디', '비', '자장가',
       '버스', '스타일', '축하', '까페', '퇴근', '2016', '상큼한', '노래방', '찾아오는DJ',
       'RNBSOUL', '상큼', '청량한', 'EDM', 'deep', '한국힙합', '아픔', '밝은', '혼자',
       '기분전환', '찬양', '아이돌', '부드러운', '눈오는날', '귀르가즘', '여름노래', '댄스댄스', 'bar',
       '크리스마스캐롤', '테라스', 'electronica', '연휴', '봄비', '가을', '북카페', '알앤비',
       '토닥토닥', '장마', '트렌디', '꿀잠', '잔잔', '하우스', '와인', '생일', '국외', '고백',
       '신남', '봄노래', '쓸쓸', '얼터너티브', '느낌있는', '성탄절', '브금', '불면증', '귀성길',
       '에이핑크', '디스코', '인기', '달달', '소울', '책읽을때', '슬픔', '운동', '사랑노래', '락',
       '잔잔한노래', '여름밤', '쌀쌀한', '시원한', '저녁', '낮잠', '일렉', '캐롤', '방콕',
       '메리크리스마스', '기분좋은', '따뜻하게', '빌로우', '아무로나미에', '장르구분없이', '월요병', '분위기',
       '청량', '페스티벌', '추천곡', '내적댄스', '국힙', '외로움', '클럽', '즐거운', '맑은', '스포츠',
       '열대야', '오르골', '감성발라드', '밤', '시작', '브릿팝', '산뜻한', 'EDMFloor', '빗소리',
       '쓸쓸함', '조용한', '낙엽', '겨울밤', '좋아요', '2019', '몽환', '블랙뮤직', '겨울노래',
       '겨울', '휴일', '태교', '팝송', '새벽감성', '바캉스', '그리움', '추천', 'Lounge',
       '플레이리스트', 'dance', '달달한', '신나는노래', '하늘', 'Instrumental', '그루브',
       '치유', '봄', '퓨전재즈', '회식', '일렉트로니카', '잔잔한', '힙합엘이', '힙한', '힘들때',
       '설렘', '취향저격', '독서', '썸', '차분', '목소리', '마음', '내한', '랩', '더위', '따듯한',
       '띵곡들', '베스트', '봄나들이', '인디팝', '연주곡', '셋리스트', '감성', '장윤정', '후회',
       '바람', '헬스', '지칠때', '흐린날', '감성적인', '유산슬', '임영웅', '집콕', '에너지',
       '몽환적인', 'Christmas', '해외일렉트로니카', '크리스마스', '바다', '케이팝', '기분업',
       '흥폭발', '겨울감성', '어린이집', '숨은명곡', 'OST', '2000', '고막여친', '춤', '휴가',
       'bgm', '트랩', '연인', '비오는날듣기좋은노래', '하루', '가족', '슬픈', 'Pop', '집중',
       '눈물', '아침', '카페뮤직', '두근두근', 'Rock', '차분한', '출근길', '이별', 'house',
       '기분', '스트레스', '봄날', '잠', 'ballad', '음색', '달콤', '인디음악', '기타',
       '다이어트', '띵곡', '떼창', '오후', '시험', '숙면', '회상', '대세', '캐럴', '취저',
       '달달한노래', '꿀성대', '희망', '팝송모음', '흥', '설레임', '힙합', '애창곡', '카페', '매장',
       '음색깡패', '크리스마스노래', '스웩', '오늘', '음악', '1990', '신나는음악', '유니크', '퇴근길',
       '신나', '잠잘때', '공부', '설날', '힘이_나는', '달콤한', '주제곡', '사랑', '발라드', '생각',
       '여름', '힐링', '여자아이돌', '방탄', '센치', '고백송', '커플', '첫사랑', '조깅', '지하철',
       '위로', '매장음악', '좋은노래', '가사', '데이트', '유산소', '트로피컬', '리드미컬', '솔로',
       '세련된', '비트', '스타일리시', '야경', '나들이', '편안한', '휘트니스', '영국', '일상']

# Commented out IPython magic to ensure Python compatibility.
# %time predictions = {_tag: svd_recommender(_tag) for _tag in test_tags}

2900 / 358

# predictions[611]

df_svd_result = df_result2[['tag', 'true']].copy()



df_svd_result['result'] = df_svd_result.tag.map(lambda x: predictions.get(x))

df_svd_result

df_svd_result['k50'] = [np.intersect1d(pred, true).shape[0] for pred, true in zip(df_svd_result.result, df_svd_result.true)]
df_svd_result['k25'] = [np.intersect1d(pred[:25], true).shape[0] for pred, true in zip(df_svd_result.result, df_svd_result.true)]
df_svd_result['k10'] = [np.intersect1d(pred[:10], true).shape[0] for pred, true in zip(df_svd_result.result, df_svd_result.true)]

df_svd_result['recall@50'] = df_svd_result.k50 / df_svd_result.true.map(lambda x: len(x))
df_svd_result['recall@25'] = df_svd_result.k25 / df_svd_result.true.map(lambda x: len(x))
df_svd_result['recall@10'] = df_svd_result.k10 / df_svd_result.true.map(lambda x: len(x))

df_svd_result['precision@50'] = df_svd_result.k50 / 50
df_svd_result['precision@25'] = df_svd_result.k25 / 25
df_svd_result['precision@10'] = df_svd_result.k10 / 10

df_svd_result.mean()

df_svd_result.to_json(get_path('svd_result_final.json'))

df_svd_result.sort_values('k50', ascending=False).head(50)

df_result2.sort_values('k50', ascending=False).tail(50)

